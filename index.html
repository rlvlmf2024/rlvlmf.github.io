<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>RL-VLM-F</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">


                        <!-- <h1 class="title is-1 publication-title">RoboGen: Towards Unleashing Infinite Data for Robot Learning via Generative Simulation</h1> -->
                        <h1 class="title is-1 publication-title">
                          <span style="color: rgb(239, 9, 9);">R</span><span style="color: rgb(228, 93, 14);">L</span><span style="color: rgb(252, 233, 28);">-</span><span style="color: rgb(12, 234, 27);">V</span><span style="color: rgb(18, 204, 246);">L</span><span style="color: rgb(9, 123, 238);">M</span><span style="color: rgb(100, 19, 239);">-</span><span style="color: rgb(179, 11, 240);">F</span>: Reinforcement Learning from Vision Language Foundation Model Feedback
                        </h1>
                        <!-- <h3 class="title is-4 conference-authors"><a target="_blank" href="https://icml.cc/">ICML 2023</a>
                    </h3> -->
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a target="_blank" href="https://yufeiwang63.github.io/"> Yufei Wang</a><sup>*1</sup>,
                                <a target="_blank"  href="https://rlvlmf2024.github.io">Zhanyi Sun</a><sup>*1</sup>,
                                <a target="_blank" href="https://jesbu1.github.io/">Jesse Zhang</a><sup>2</sup>,
                                <a target="_blank" href="https://www.zhou-xian.com/">Xian Zhou</a><sup>1</sup>,
                                <br>
                                <a target="_blank" href="https://ebiyik.github.io/">Erdem Bıyık</a><sup>2</sup>,
                                <a target="_blank" href="http://davheld.github.io/">David Held</a><sup>&dagger;1</sup>,
                                <a target="_blank" href="https://zackory.com/">Zackory Erickson</a><sup>&dagger;1</sup>,
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>CMU, </span>
                            <span class="author-block"><sup>2</sup>University of Southern California</span>
                        </div>
                        <div class="is-size-6 publication-authors">
                            <span class="author-block"><sup>*</sup>Equal Contribution </span>
                            <span class="author-block"><sup>&dagger;</sup>Equal Advising </span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- TODO REPLACE ALL LINKS -->
                                <span class="link-block">
                                    <a target="_blank" href="https://arxiv.org/abs/2402.03681"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a target="_blank" href="https://rlvlmf2024.github.io"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section" style="padding: 0">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <video poster="" id="" autoplay controls loop width="100%" playbackRate=2.0 style="border-radius: 5px;">
                    <source src="videos/teaser.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 125%">
                          Reward engineering has long been a challenge in Reinforcement Learning (RL) research, 
                          as it often requires extensive human effort and iterative processes of trial-and-error to design effective reward functions. 
                          In this paper, we propose RL-VLM-F, a method that automatically generates reward functions for agents to learn new tasks, 
                          using only a text description of the task goal and the agent’s visual observations, 
                          by leveraging feedbacks from vision language foundation models (VLMs). 
                          The key to our approach is to query these models to give preferences over pairs of the agent’s image observations based on the text
                          description of the task goal, and then learn a reward function from the preference labels, 
                          rather than directly prompting these models to output a raw reward score, 
                          which can be noisy and inconsistent. 
                          We demonstrate that RL-VLM-F successfully produces effective rewards and policies across various domains — including classic control, as well as manipulation of rigid, articulated,
                          and deformable objects — without the need for human supervision, outperforming prior methods
                          that use large pretrained models for reward generation under the same assumptions.
<br>
<br>

                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- rollout examples of ours and baselines for each task -->
    <section class="section">
      <div class="container is-max-widescreen">
          <div class="rows">
              <div class="rows is-centered ">
                  <div class="row is-full-width">
                      <h2 class="title is-3"><span class="dvima">RL-VLM-F: Prompts and Policies</span></h2>
                      <p style="font-size: 125%">
                        Below we show the policy rollouts from our method and baselines on seven tasks including rigid, articulated, and deformable object manipulation. 
                        For each task, we show a short text description of task goal, which when combined with a template prompt forms the full prompt that we use to query the VLM for preferences. 
                      </p>
                  </div>
              </div>
          </div>
          <br>
        <!-- Subsection for Fold Cloth Diagonally -->
        <div style="margin-bottom: 20px;">
          <h2 style="font-size: 21px; margin-bottom: 10px;">Fold Cloth Diagonally</h2>
          <div>
            <pre class="p-1 scrollable"><code class="language-markdown" id="answer-1">"to fold the cloth diagonally from top left corner to bottom right corner"</code></pre>
          </div>
          <br>
          <div style="display: flex; justify-content: space-between; margin-bottom: 20px;">
            <div style="text-align: center; width: 18%;"> <!-- Adjust width for resizing GIFs -->
              <img src="gifs/ours_fold_cloth.gif" alt="Result 1" style="max-width: 100%; height: auto;">
              <div><strong>RL-VLM-F (ours)</strong></div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/vlm-score_fold_cloth.gif" alt="Result 3" style="max-width: 100%; height: auto;">
              <div>VLM Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/clip_fold_cloth.gif" alt="Result 4" style="max-width: 100%; height: auto;">
              <div>CLIP Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/blip2_fold_cloth.gif" alt="Result 5" style="max-width: 100%; height: auto;">
              <div>BLIP-2 Score</div>
            </div>
          </div>
        </div>
        <br>
        <!-- Subsection for Fold Cloth Diagonally -->
        <div style="margin-bottom: 20px;">
          <h2 style="font-size: 21px; margin-bottom: 10px;">Straighten Rope</h2>
          <div>
            <pre class="p-1 scrollable"><code class="language-markdown" id="answer-1">"to straighten the blue rope"</code></pre>
          </div>
          <br>
          <div style="display: flex; justify-content: space-between; margin-bottom: 20px;">
            <div style="text-align: center; width: 18%;"> <!-- Adjust width for resizing GIFs -->
              <img src="gifs/ours_rope.gif" alt="Result 1" style="max-width: 100%; height: auto;">
              <div><strong>RL-VLM-F (ours)</strong></div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/vlm-score_rope.gif" alt="Result 3" style="max-width: 100%; height: auto;">
              <div>VLM Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/clip_rope.gif" alt="Result 4" style="max-width: 100%; height: auto;">
              <div>CLIP Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/blip2_rope.gif" alt="Result 5" style="max-width: 100%; height: auto;">
              <div>BLIP-2 Score</div>
            </div>
          </div>
        </div>
        <br>
        <!-- Subsection for Pass Water without Spilling -->
        <div style="margin-bottom: 20px;">
          <h2 style="font-size: 21px; margin-bottom: 10px;">Pass Water without Spilling</h2>
          <div>
            <pre class="p-1 scrollable"><code class="language-markdown" id="answer-1">"to move the container, which holds water, to be as close to the red circle as possible without causing too many water droplets to spill"</code></pre>
          </div>
          <br>
          <div style="display: flex; justify-content: space-between; margin-bottom: 20px;">
            <div style="text-align: center; width: 18%;"> <!-- Adjust width for resizing GIFs -->
              <img src="gifs/ours_water.gif" alt="Result 1" style="max-width: 100%; height: auto;">
              <div><strong>RL-VLM-F (ours)</strong></div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/vlm-score_water.gif" alt="Result 3" style="max-width: 100%; height: auto;">
              <div>VLM Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/clip_water.gif" alt="Result 4" style="max-width: 100%; height: auto;">
              <div>CLIP Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/blip2_water.gif" alt="Result 5" style="max-width: 100%; height: auto;">
              <div>BLIP-2 Score</div>
            </div>
          </div>
        </div>
        <br>
        <!-- Subsection for Move Soccer Ball into Goal -->
        <div style="margin-bottom: 20px;">
          <h2 style="font-size: 21px; margin-bottom: 10px;">Move Soccer Ball into Goal </h2>
          <div>
            <pre class="p-1 scrollable"><code class="language-markdown" id="answer-1">"to move the soccer ball into the goal"</code></pre>
          </div>
          <br>
          <div style="display: flex; justify-content: space-between; margin-bottom: 20px;">
            <div style="text-align: center; width: 18%;"> <!-- Adjust width for resizing GIFs -->
              <img src="gifs/ours_soccer.gif" alt="Result 1" style="max-width: 100%; height: auto;">
              <div><strong>RL-VLM-F (ours)</strong></div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/vlm-score_soccer.gif" alt="Result 3" style="max-width: 100%; height: auto;">
              <div>VLM Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/clip_soccer.gif" alt="Result 4" style="max-width: 100%; height: auto;">
              <div>CLIP Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/blip2_soccer.gif" alt="Result 5" style="max-width: 100%; height: auto;">
              <div>BLIP-2 Score</div>
            </div>
          </div>
        </div>
        <br>
        <!-- Subsection for Open Drawer-->
        <div style="margin-bottom: 20px;">
          <h2 style="font-size: 21px; margin-bottom: 10px;">Open Drawer</h2>
          <div>
            <pre class="p-1 scrollable"><code class="language-markdown" id="answer-1">"to open the drawer"</code></pre>
          </div>
          <br>
          <div style="display: flex; justify-content: space-between; margin-bottom: 20px;">
            <div style="text-align: center; width: 18%;"> <!-- Adjust width for resizing GIFs -->
              <img src="gifs/ours_open_drawer.gif" alt="Result 1" style="max-width: 100%; height: auto;">
              <div><strong>RL-VLM-F (ours)</strong></div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/vlm-score_open_drawer.gif" alt="Result 3" style="max-width: 100%; height: auto;">
              <div>VLM Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/clip_open_drawer.gif" alt="Result 4" style="max-width: 100%; height: auto;">
              <div>CLIP Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/blip2_open_drawer.gif" alt="Result 5" style="max-width: 100%; height: auto;">
              <div>BLIP-2 Score</div>
            </div>
          </div>
        </div>
        <br>
        <!-- Subsection for Sweep Cube into Hole -->
        <div style="margin-bottom: 20px;">
          <h2 style="font-size: 21px; margin-bottom: 10px;">Sweep Cube into Hole</h2>
          <div>
            <pre class="p-1 scrollable"><code class="language-markdown" id="answer-1">"to minimize the distance between the green cube and the hole"</code></pre>
          </div>
          <br>
          <div style="display: flex; justify-content: space-between; margin-bottom: 20px;">
            <div style="text-align: center; width: 18%;"> <!-- Adjust width for resizing GIFs -->
              <img src="gifs/ours_sweep_into.gif" alt="Result 1" style="max-width: 100%; height: auto;">
              <div><strong>RL-VLM-F (ours)</strong></div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/vlm-score_sweep_into.gif" alt="Result 3" style="max-width: 100%; height: auto;">
              <div>VLM Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/clip_sweep_into.gif" alt="Result 4" style="max-width: 100%; height: auto;">
              <div>CLIP Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/blip2_sweep_into.gif" alt="Result 5" style="max-width: 100%; height: auto;">
              <div>BLIP-2 Score</div>
            </div>
          </div>
        </div>
        <br>
        <!-- Subsection for CartPole -->
        <div style="margin-bottom: 20px;">
          <h2 style="font-size: 21px; margin-bottom: 10px;">CartPole</h2>
          <div>
            <pre class="p-1 scrollable"><code class="language-markdown" id="answer-1">"to balance the brown pole on the black cart to be upright"</code></pre>
          </div>
          <br>
          <div style="display: flex; justify-content: space-between; margin-bottom: 20px;">
            <div style="text-align: center; width: 18%;"> <!-- Adjust width for resizing GIFs -->
              <img src="gifs/ours_cartpole.gif" alt="Result 1" style="max-width: 100%; height: auto;">
              <div><strong>RL-VLM-F (ours)</strong></div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/vlm-score_cartpole.gif" alt="Result 3" style="max-width: 100%; height: auto;">
              <div>VLM Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/clip_cartpole.gif" alt="Result 4" style="max-width: 100%; height: auto;">
              <div>CLIP Score</div>
            </div>
            <div style="text-align: center; width: 18%;">
              <img src="gifs/blip2_cartpole.gif" alt="Result 5" style="max-width: 100%; height: auto;">
              <div>BLIP-2 Score</div>
            </div>
          </div>
        </div>
        <br>
      </div>
    </section>


    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">RL-VLM-F Components</span></h2>
                        <div class="columns is-centered has-text-centered">
                          <video poster="" id="" autoplay controls loop width="100%" playbackRate=2.0 style="border-radius: 5px;">
                              <source src="videos/overall_components.mp4" type="video/mp4">
                          </video>
                        </div>
                        <br>
                        <span style="font-size: 125%"><strong>Overview: </strong>RL-VLM-F automatically generates
                          reward functions for agents to learn new tasks, using only a text description of the task goal and the
                          agent’s visual observations, by leveraging feedbacks from vision language foundation models
                          (VLMs). The key to our approach is to query
                          these models to give preferences over pairs of
                          the agent’s image observations based on the text
                          description of the task goal, and then learn a reward function from the preference labels. We use Preference-based RL
                          method to learn the policy and reward function at the same time. 
                        </span>
                        <br>
                        <br>
                        <h2 class="title is-4" style="text-align: center;"><span class="dvima">RL-VLM-F Query Design</span></h2>
                        <img src="imgs/rl-vlm-f_query.jpeg" class="interpolation-image" alt=""
                        style="display: block; margin-left: auto; margin-right: auto; max-width: 80%;" />
                        <br>
                        <span style="font-size: 125%"><strong>RL-VLM-F Two-stage query: </strong>We query the VLM in 2 stages: 
                          First, we query the VLM to generate free-form responses comparing how well each of the two images achieves the task. 
                          Next, we prompt the VLM with the text responses from the first stage to extract a preference label over the two images.
                          We use the same query template for all tasks, with <span style="color: red;">[task description]</span> replaced by task-specific goal description. 
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    
    <section class="section">
      <div class="container is-max-widescreen">
          <div class="rows">
              <div class="rows is-centered ">
                  <div class="row is-full-width">
                      <h2 class="title is-3"><span class="dvima">Experiments and Results</span></h2>
                      <span style="font-size: 125%"> We thoroughly evaluate RL-VLM-F on a diverse set of tasks — including classic control, as well as manipulation of rigid, articulated,
                        and deformable objects — without the need for
                        human supervision, outperforming prior methods
                        that use large pretrained models for reward generation under the same assumptions
                      </span>
                      <br>
                      <br>
                      <h2 class="title is-4" style="text-align: center;"><span class="dvima">Comparison to Baselines</span></h2>
                      <img src="imgs/performance.png" class="interpolation-image" alt=""
                      style="display: block; margin-left: auto; margin-right: auto; max-width: 80%;" />
                      <br>
                      <span style="font-size: 125%"> As shown in the learning curves of all compared methods on 7 tasks, RL-VLM-F outperforms all baselines in all tasks, and matches or surpasses
                        the performance of GT preference on 6 of the 7 tasks. 
                      </span>
                      <br>
                      <br>
                      <h2 class="title is-4" style="text-align: center;"><span class="dvima">Accuracy of VLM Preference Labels</span></h2>
                      <img src="imgs/labeling_errors.png" class="interpolation-image" alt=""
                      style="display: block; margin-left: auto; margin-right: auto; max-width: 80%;" />
                      <br>
                      <span style="font-size: 125%"> We provide analysis of the accuracy of the VLM preference labels, compared to ground-truth preference labels defined according
                        to the environment’s reward function. The x-axis represents different levels of differences between the image pairs, discretized into 10
                        bins, where the difference is measured as the difference between the ground-truth task progress associated with the image pairs. The
                        y-axis shows the ratio where the VLM preference labels are correct, incorrect, or when it does not have a preference over the image pairs.
                        We find that like humans, VLMs are better at evaluating two images when they are distinct from one another in terms of achieving the goal, and perform worse when the two images are very similar.
                      </span>
                      <br>
                      <br>
                      <h2 class="title is-4" style="text-align: center;"><span class="dvima">Alignment Between Learned Reward and Ground-truth Task Progress</span></h2>
                      <img src="imgs/alignment_w_gt_rew.png" class="interpolation-image" alt=""
                      style="display: block; margin-left: auto; margin-right: auto; max-width: 80%;" />
                      <br>
                      <span style="font-size: 125%"> We compare how well the learned reward by RL-VLM-F and VLM Score align with the ground-truth task progress on 3
                        MetaWorld tasks along an expert trajectory. As shown, RL-VLM-F generates rewards that align better with the ground-truth task progress.
                        The learned rewards are averaged over 3 trained reward models with different seeds, and the shaded region represents the standard error.
                      </span>
                  </div>
              </div>
          </div>
      </div>
  </section>



<section class="section" id="BibTeX">
    <div class="container is-max-widescreen content">
        <h2 class="title">BibTeX</h2>
        <pre>@article{wang2024rl,
          title={RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback},
          author={Wang, Yufei and Sun, Zhanyi and Zhang, Jesse and Xian, Zhou and Biyik, Erdem and Held, David and Erickson, Zackory},
          journal={arXiv preprint arXiv:2402.03681},
          year={2024}
        }
</pre>
    </div>
</section>

    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column">
                    <div class="content has-text-centered">
                        <p>
                            Website template borrowed from <a
                            href="https://robogen-ai.github.io/">RoboGen</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

<script>

  timeoutIds = [];

  function populateDemo(imgs, num) {
      // Get the expanded image
      var expandImg = document.getElementById("expandedImg-" + num);
      // Get the image text
      var imgText = document.getElementById("imgtext-" + num);
      var answer = document.getElementById("answer-" + num);

      // Use the same src in the expanded image as the image being clicked on from the grid
      expandImg.src = imgs.src.replace(".png", ".mp4");
      var video = document.getElementById('demo-video-' + num);
      // or video = $('.video-selector')[0];
      video.pause()
      video.load();
      video.play();
      video.removeAttribute('controls');

      console.log(expandImg.src);
      // Use the value of the alt attribute of the clickable image as text inside the expanded image
      var qa = imgs.alt.split("[sep]");
      imgText.innerHTML = qa[0];
      answer.innerHTML = "";

      // Show the container element (hidden with CSS)
      expandImg.parentElement.style.display = "block";
      for (timeoutId of timeoutIds) {
          clearTimeout(timeoutId);
      }

      // NOTE (wliang): Modified from original to read from file instead
      fetch(qa[1])
          .then(response => response.text())
          .then(contents => {
              // Call the processData function and pass the contents as an argument
              typeWriter(contents, 0, qa[0], num, "imgtext-", "answer-");
          })
          .catch(error => console.error('Error reading file:', error));
  }

  function typeWriter(txt, i, q, num, text1, text2) {
      var imgText = document.getElementById(text1 + num);
      var answer = document.getElementById(text2 + num);
      if (imgText.innerHTML == q) {
          for (let k = 0; k < 5; k++) {
              if (i < txt.length) {
                  if (txt.charAt(i) == "\\") {
                      answer.innerHTML += "\n";
                      i += 1;
                  } else {
                      answer.innerHTML += txt.charAt(i);
                  }
                  i++;
              }
          }
          hljs.highlightAll();
          timeoutIds.push(setTimeout(typeWriter, 1, txt, i, q, num, text1, text2));
      }
  }

</script>

</html>