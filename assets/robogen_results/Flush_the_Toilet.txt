========== Generated task name and description ==========
Flush the Toilet
The robotic arm will interact with the hinge lever of the toilet to flush it

========== Scene configuration ==========
- use_table: false
- center: (1.0, 0.2, 0)
  lang: a common toilet
  name: Toilet
  on_table: false
  path: toilet.urdf
  size: 0.7
  type: urdf
- set_joint_angle_object_name: Toilet
- spatial_relationships: []
- center: (1.2, 0.4, 0)
  lang: a roll of toilet paper
  name: Toilet Paper
  on_table: false
  path: toilet_paper.obj
  size: 0.1
  type: mesh
- center: (1.5, 0.5, 0)
  lang: a bathroom towel
  name: Towel
  on_table: false
  path: towel.obj
  size: 0.3
  type: mesh
- center: (0.8, 0.8, 0)
  lang: a common bath mat
  name: Bath Mat
  on_table: false
  path: bath_mat.obj
  size: 0.4
  type: mesh

========== Task decompositions (substep: learning algorithm type, action space) ==========
approach the toilet lever: primitive, none
grasp the toilet lever: primitive, none
flush the toilet by pushing the lever: reward, delta_translation

========== Reward and primitives ==========
- approach_the_toilet_lever
    def execute(self):
        rgbs, final_state = approach_object_link(self, "Toilet", "link_0")  
        success = gripper_close_to_object_link(self, "Toilet", "link_0")

        return rgbs, final_state, success

- grasp_the_toilet_lever
    def execute(self):
        rgbs, final_state = grasp_object_link(self, "Toilet", "link_0")  
        grasped_object, grasped_link = get_grasped_object_and_link_name(self)
        success = (grasped_object == "Toilet".lower() and grasped_link == "link_0".lower())

        return rgbs, final_state, success

- flush_the_toilet_by_pushing_the_lever
    def _compute_reward(self):
        # This reward encourages the end-effector to stay near the lever to grasp it.
        eef_pos = get_eef_pos(self)[0]
        lever_pos = get_link_state(self, "Toilet", "link_0")
        reward_near = -np.linalg.norm(eef_pos - lever_pos)
        
        # Get the joint state of the lever. The semantics and the articulation tree show that joint_0 connects link_0 and is the joint that controls the rotation of the lever.
        joint_angle = get_joint_state(self, "Toilet", "joint_0") 
        # The reward is the negative distance between the current joint angle and the joint angle when the lever is fully pushed (upper limit).
        joint_limit_low, joint_limit_high = get_joint_limit(self, "Toilet", "joint_0")
        target_joint_angle = joint_limit_high
        
        diff = np.abs(joint_angle - target_joint_angle)
        reward_joint =  -diff
        
        reward = reward_near + 5 * reward_joint
        
        success = diff < 0.1 * (joint_limit_high - joint_limit_low)
        
        return reward, success

