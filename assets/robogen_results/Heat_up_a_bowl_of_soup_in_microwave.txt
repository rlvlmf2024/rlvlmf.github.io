========== Generated task name and description ==========
Heat up a bowl of soup in microwave
The robot arm places a bowl of soup inside the microwave, closes the door, and sets the microwave timer to heat the soup for an appropriate amount of time

========== Scene configuration ==========
- use_table: true
- center: (0.7, 0.6, 0)
  lang: a common microwave
  name: Microwave
  on_table: true
  path: microwave.urdf
  size: 0.6
  type: urdf
- center: (0.3, 0.2, 0)
  lang: a bowl of tomato soup
  name: Bowl of soup
  on_table: true
  path: bowl_of_soup.obj
  size: 0.15
  type: mesh
- joint_0: '0'
  joint_1: '0'
  set_joint_angle_object_name: Microwave
- spatial_relationships: []
- center: (0.8, 0.3, 0)
  lang: a common kitchen cup
  name: cup
  on_table: true
  path: cup.obj
  size: 0.1
  type: mesh
- center: (0.5, 0.2, 0)
  lang: a common kitchen spoon
  name: spoon
  on_table: true
  path: spoon.obj
  size: 0.05
  type: mesh
- center: (1.8, 0.5, 0)
  lang: a common kitchen refrigerator
  name: Refrigerator
  on_table: false
  path: refrigerator.obj
  size: 1.7
  type: urdf

========== Task decompositions (substep: learning algorithm type, action space) ==========
grasp the microwave door: primitive, none
open the microwave door: reward, delta_translation
grasp the bowl of soup: primitive, none
put the bowl of soup into the microwave: reward, target_location
grasp the microwave door again: primitive, none
close the microwave door: reward, delta_translation
grasp the microwave timer knob: primitive, none
turn the microwave timer knob to set a desired heating time: reward, delta_translation

========== Reward and primitives ==========
- grasp_the_microwave_door
    def execute(self):
        rgbs, final_state = grasp_object_link(self, "Microwave", "link_0")  
        grasped_object, grasped_link = get_grasped_object_and_link_name(self)
        success = (grasped_object == "Microwave".lower() and grasped_link == "link_0".lower())

        return rgbs, final_state, success

- open_the_microwave_door
    def _compute_reward(self):
        # This reward encourages the end-effector to stay near the door to grasp it.
        eef_pos = get_eef_pos(self)[0]
        door_pos = get_link_state(self, "Microwave", "link_0")
        reward_near = -np.linalg.norm(eef_pos - door_pos)
        
        # Get the joint state of the door. The semantics and the articulation tree show that joint_0 connects link_0 and is the joint that controls the rotation of the door.
        joint_angle = get_joint_state(self, "Microwave", "joint_0") 
        # The reward is the negative distance between the current joint angle and the joint angle when the door is fully open (upper limit).
        joint_limit_low, joint_limit_high = get_joint_limit(self, "Microwave", "joint_0")
        target_joint_angle = joint_limit_high
        diff = np.abs(joint_angle - target_joint_angle)
        reward_joint =  -diff
        
        reward = reward_near + 5 * reward_joint
        
        success = diff < 0.1 * (joint_limit_high - joint_limit_low)
        
        return reward, success

- grasp_the_bowl_of_soup
    def execute(self):
        rgbs, final_state = grasp_object(self, "Bowl of soup")
        success = get_grasped_object_name(self) == "Bowl of soup".lower()

        return rgbs, final_state, success

- put_the_bowl_of_soup_into_the_microwave
    def _compute_reward(self):
        # Get the current bowl position
        bowl_position = get_position(self, "Bowl of soup")
        
        # This reward encourages the end-effector to stay near the bowl to grasp it.
        eef_pos = get_eef_pos(self)[0]
        reward_near = -np.linalg.norm(eef_pos - bowl_position)
        
        # Get the microwave body bounding box
        min_aabb, max_aabb = get_bounding_box_link(self, "Microwave", "link_3") # from the semantics, link_3 is the body of the microwave.
        diff = np.array(max_aabb) - np.array(min_aabb)
        min_aabb = np.array(min_aabb) + 0.05 * diff  # shrink the bounding box a bit
        max_aabb = np.array(max_aabb) - 0.05 * diff
        center = (np.array(max_aabb) + np.array(min_aabb)) / 2
        
        # another reward is one if the bowl is inside the microwave bounding box
        reward_in = 0
        if in_bbox(self, bowl_position, min_aabb, max_aabb): reward_in += 1
        
        # another reward is to encourage the robot to move the bowl to be near the microwave
        reward_reaching = -np.linalg.norm(center - bowl_position)
        
        # The task is considered to be successful if the bowl is inside the microwave bounding box
        success = in_bbox(self, bowl_position, min_aabb, max_aabb)
        
        # We give more weight to reward_in, which is the major goal of the task.
        reward = 5 * reward_in + reward_reaching + reward_near
        return reward, success

- grasp_the_microwave_door_again
    def execute(self):
        rgbs, final_state = grasp_object_link(self, "Microwave", "link_0")  
        grasped_object, grasped_link = get_grasped_object_and_link_name(self)
        success = (grasped_object == "Microwave".lower() and grasped_link == "link_0".lower())

        return rgbs, final_state, success

- close_the_microwave_door
    def _compute_reward(self):
        # This reward encourages the end-effector to stay near the door
        eef_pos = get_eef_pos(self)[0]
        door_pos = get_link_state(self, "Microwave", "link_0")
        reward_near = -np.linalg.norm(eef_pos - door_pos)
        
        # Get the joint state of the door. The semantics and the articulation tree show that joint_0 connects link_0 and is the joint that controls the rotation of the door.
        joint_angle = get_joint_state(self, "Microwave", "joint_0") 
        # The reward encourages the robot to make joint angle of the door to be the lower limit to close it.
        joint_limit_low, joint_limit_high = get_joint_limit(self, "Microwave", "joint_0")
        target_joint_angle = joint_limit_low
        
        diff = np.abs(target_joint_angle - joint_angle)
        reward_joint =  -diff
        
        reward = reward_near + 5 * reward_joint
        
        success = diff < 0.1 * (joint_limit_high - joint_limit_low)       
        
        return reward, success

- grasp_the_microwave_timer_knob
    def execute(self):
        rgbs, final_state = grasp_object_link(self, "Microwave", "link_1")  
        grasped_object, grasped_link = get_grasped_object_and_link_name(self)
        success = (grasped_object == "Microwave".lower() and grasped_link == "link_1".lower())

        return rgbs, final_state, success

- turn_the_microwave_timer_knob_to_set_a_desired_heating_time
    def _compute_reward(self):
        # This reward encourages the end-effector to stay near the knob to grasp it.
        eef_pos = get_eef_pos(self)[0]
        knob_pos = get_link_state(self, "Microwave", "link_1")
        reward_near = -np.linalg.norm(eef_pos - knob_pos)
        
        joint_angle = get_joint_state(self, "Microwave", "joint_1") 
        
        joint_limit_low, joint_limit_high = get_joint_limit(self, "Microwave", "joint_1")
        desired_time = joint_limit_high # + (joint_limit_high - joint_limit_low)  / 2 # We assume the target desired time is half of the joint angle. It can also be 1/3, or other values between joint_limit_low and joint_limit_high. 
        
        # The reward is the negative distance between the current joint angle and the joint angle of the desired time.
        diff = np.abs(joint_angle - desired_time)
        reward_joint =  -diff
        
        reward = reward_near + 5 * reward_joint
        
        success = diff < 0.1 * (joint_limit_high - joint_limit_low)
        
        return reward, success

